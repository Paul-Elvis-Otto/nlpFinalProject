<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>REP or DEM   LSTM classification report</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8a894fcc3cb5e37eb5bf30def131be2f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script async="" src="https://hypothes.is/embed.js"></script>
<script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="REP or DEM &amp;amp;lt;br&amp;gt; LSTM classification report">
<meta name="citation_author" content="Paul Elvis Otto">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Literate programming;,citation_author=Donald E. Knuth;,citation_publication_date=1984-05;,citation_cover_date=1984-05;,citation_year=1984;,citation_fulltext_html_url=https://doi.org/10.1093/comjnl/27.2.97;,citation_issue=2;,citation_doi=10.1093/comjnl/27.2.97;,citation_issn=0010-4620;,citation_volume=27;,citation_journal_title=Comput. J.;,citation_publisher=Oxford University Press, Inc.;">
</head>

<body class="quarto-light">

<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">REP or DEM <br> LSTM classification report</h1>
          </div>

    
    <div class="quarto-title-meta-container">
      <div class="quarto-title-meta-column-start">
            <div class="quarto-title-meta-author">
          <div class="quarto-title-meta-heading">Author</div>
          <div class="quarto-title-meta-heading">Affiliation</div>
          
                <div class="quarto-title-meta-contents">
            <p class="author">Paul Elvis Otto </p>
          </div>
                <div class="quarto-title-meta-contents">
                    <p class="affiliation">
                        Duke University / Hertie School
                      </p>
                  </div>
                    </div>
        
        <div class="quarto-title-meta">

                      
          
                
              </div>
      </div>
      <div class="quarto-title-meta-column-end quarto-other-formats-target">
      <div class="quarto-alternate-formats"><div class="quarto-title-meta-heading">Other Formats</div><div class="quarto-title-meta-contents"><p><a href="index.docx"><i class="bi bi-file-word"></i>MS Word</a></p></div><div class="quarto-title-meta-contents"><p><a href="index.pdf"><i class="bi bi-file-pdf"></i>Typst</a></p></div><div class="quarto-title-meta-contents"><p><a href="index-meca.zip" data-meca-link="true"><i class="bi bi-archive"></i>MECA Bundle</a></p></div></div></div>
    </div>



    <div class="quarto-other-links-text-target">
    </div>  </div>
</header><div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#intro" id="toc-intro" class="nav-link active" data-scroll-target="#intro">Intro</a></li>
  <li><a href="#sec-data-prep" id="toc-sec-data-prep" class="nav-link" data-scroll-target="#sec-data-prep">Data Preparation</a></li>
  <li><a href="#sec-eda" id="toc-sec-eda" class="nav-link" data-scroll-target="#sec-eda">EDA</a></li>
  <li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification">Model specification</a>
  <ul class="collapse">
  <li><a href="#tokenization-and-feature-extraction" id="toc-tokenization-and-feature-extraction" class="nav-link" data-scroll-target="#tokenization-and-feature-extraction">Tokenization and feature extraction</a></li>
  <li><a href="#bidirectional-lstm-encoder" id="toc-bidirectional-lstm-encoder" class="nav-link" data-scroll-target="#bidirectional-lstm-encoder">Bidirectional LSTM encoder</a></li>
  <li><a href="#masked-mean-pooling" id="toc-masked-mean-pooling" class="nav-link" data-scroll-target="#masked-mean-pooling">Masked mean pooling</a></li>
  <li><a href="#classification-head" id="toc-classification-head" class="nav-link" data-scroll-target="#classification-head">Classification head</a></li>
  <li><a href="#training-objective" id="toc-training-objective" class="nav-link" data-scroll-target="#training-objective">Training objective</a></li>
  <li><a href="#computational-considerations" id="toc-computational-considerations" class="nav-link" data-scroll-target="#computational-considerations">Computational considerations</a></li>
  </ul></li>
  <li><a href="#data-pipeline" id="toc-data-pipeline" class="nav-link" data-scroll-target="#data-pipeline">Data Pipeline</a>
  <ul class="collapse">
  <li><a href="#training-loop" id="toc-training-loop" class="nav-link" data-scroll-target="#training-loop">Training Loop</a></li>
  <li><a href="#implementation-in-code" id="toc-implementation-in-code" class="nav-link" data-scroll-target="#implementation-in-code">Implementation in Code</a></li>
  </ul></li>
  <li><a href="#sec-nbb" id="toc-sec-nbb" class="nav-link" data-scroll-target="#sec-nbb">Naive Bayes Baseline</a>
  <ul class="collapse">
  <li><a href="#model-description" id="toc-model-description" class="nav-link" data-scroll-target="#model-description">Model description</a></li>
  </ul></li>
  <li><a href="#empirical-assessments" id="toc-empirical-assessments" class="nav-link" data-scroll-target="#empirical-assessments">Empirical Assessments</a>
  <ul class="collapse">
  <li><a href="#bilstm" id="toc-bilstm" class="nav-link" data-scroll-target="#bilstm">BiLSTM</a></li>
  <li><a href="#qualitative-analysis" id="toc-qualitative-analysis" class="nav-link" data-scroll-target="#qualitative-analysis">Qualitative Analysis</a></li>
  <li><a href="#naive-bayes-baseline" id="toc-naive-bayes-baseline" class="nav-link" data-scroll-target="#naive-bayes-baseline">Naive Bayes Baseline</a></li>
  <li><a href="#comparative-perspective" id="toc-comparative-perspective" class="nav-link" data-scroll-target="#comparative-perspective">Comparative perspective</a></li>
  </ul></li>
  <li><a href="#limitations-and-possible-extensions" id="toc-limitations-and-possible-extensions" class="nav-link" data-scroll-target="#limitations-and-possible-extensions">Limitations and possible extensions</a>
  <ul class="collapse">
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#extensions" id="toc-extensions" class="nav-link" data-scroll-target="#extensions">Extensions</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#external-sources-used" id="toc-external-sources-used" class="nav-link" data-scroll-target="#external-sources-used">External sources used</a></li>
  </ul>
<div class="quarto-alternate-notebooks"><h2>Notebooks</h2><ul><li><a href="index-preview.html"><i class="bi bi-journal-code"></i>Article Notebook</a></li></ul></div></nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content quarto-banner-title-block" id="quarto-document-content">



  


<section id="intro" class="level2">
<h2 class="anchored" data-anchor-id="intro">Intro</h2>
<p>Classifying short social-media texts is a standard NLP task and a useful testbed for comparing lexical and sequence-based models. This project predicts whether a tweet posted by a member of the 112th U.S. Congress was authored by a Democrat or a Republican. The dataset, sourced from Harvard Dataverse, contains each post’s text as well as metadata on the author’s party and chamber (House vs.&nbsp;Senate).</p>
<p>The main model is a bidirectional LSTM classifier operating over contextual token embeddings. Instead of learning word representations from scratch, the pipeline uses a pretrained MiniLM Transformer as a frozen feature extractor (loaded via the MLX-Embeddings/Hugging Face adaptation). The BiLSTM and linear classification head are trained on top of these fixed embeddings. As a transparent baseline, a Multinomial Naive Bayes model with TF–IDF n-gram features is implemented on the same train/validation/test split, and its performance is compared to the BiLSTM in the empirical assessment section.</p>
<p>To situate the task, an exploratory data analysis is presented in <a href="#sec-eda" class="quarto-xref">Section&nbsp;3</a>. The text preprocessing and label normalization used to construct the modeling dataset are described in <a href="#sec-data-prep" class="quarto-xref">Section&nbsp;2</a>.</p>
</section>
<section id="sec-data-prep" class="level2">
<h2 class="anchored" data-anchor-id="sec-data-prep">Data Preparation</h2>
<p>To ensure the data is usable and not influenced by elements such as dates, mentions, or links, each post was cleaned using a set of regular expressions. The cleaning script is available in the model’s repository. The cleaned dataset excludes the following:</p>
<ul>
<li>Dates</li>
<li>Mentions</li>
<li>Hashtags</li>
<li>URLs</li>
</ul>
<p>The data is read in already cleaned into the model pipeline.</p>
</section>
<section id="sec-eda" class="level2">
<h2 class="anchored" data-anchor-id="sec-eda">EDA</h2>
<p>This section provides an initial overview of the dataset by examining its basic structure and several descriptive metrics.</p>
<p>The dataset has a dimension of 334606, 5. To begin, we look at how posts are distributed across chambers and parties. The overall distribution is visualized in <a href="#fig-post-dist" class="quarto-xref">Figure&nbsp;1</a>.</p>
<div id="cell-fig-post-dist" class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-post-dist" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-post-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-post-dist-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;1: Distribution of posts by chamber and party"><img src="index_files/figure-html/fig-post-dist-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-post-dist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Distribution of posts by chamber and party
</figcaption>
</figure>
</div>
</div>
<a class="quarto-notebook-link" id="nblink-1" href="index-preview.html#cell-fig-post-dist">Source: Article Notebook</a></div>
<p>A more detailed breakdown of total posts per chamber and party is provided in the table below:</p>
<div class="cell">
<div class="cell-output-display">
<div id="uvwbajtdwn" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#uvwbajtdwn table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#uvwbajtdwn thead, #uvwbajtdwn tbody, #uvwbajtdwn tfoot, #uvwbajtdwn tr, #uvwbajtdwn td, #uvwbajtdwn th {
  border-style: none;
}

#uvwbajtdwn p {
  margin: 0;
  padding: 0;
}

#uvwbajtdwn .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#uvwbajtdwn .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#uvwbajtdwn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#uvwbajtdwn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#uvwbajtdwn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uvwbajtdwn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uvwbajtdwn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#uvwbajtdwn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#uvwbajtdwn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#uvwbajtdwn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#uvwbajtdwn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#uvwbajtdwn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#uvwbajtdwn .gt_spanner_row {
  border-bottom-style: hidden;
}

#uvwbajtdwn .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#uvwbajtdwn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#uvwbajtdwn .gt_from_md > :first-child {
  margin-top: 0;
}

#uvwbajtdwn .gt_from_md > :last-child {
  margin-bottom: 0;
}

#uvwbajtdwn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#uvwbajtdwn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#uvwbajtdwn .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#uvwbajtdwn .gt_row_group_first td {
  border-top-width: 2px;
}

#uvwbajtdwn .gt_row_group_first th {
  border-top-width: 2px;
}

#uvwbajtdwn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uvwbajtdwn .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#uvwbajtdwn .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#uvwbajtdwn .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uvwbajtdwn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#uvwbajtdwn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#uvwbajtdwn .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#uvwbajtdwn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#uvwbajtdwn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#uvwbajtdwn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uvwbajtdwn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#uvwbajtdwn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#uvwbajtdwn .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#uvwbajtdwn .gt_left {
  text-align: left;
}

#uvwbajtdwn .gt_center {
  text-align: center;
}

#uvwbajtdwn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#uvwbajtdwn .gt_font_normal {
  font-weight: normal;
}

#uvwbajtdwn .gt_font_bold {
  font-weight: bold;
}

#uvwbajtdwn .gt_font_italic {
  font-style: italic;
}

#uvwbajtdwn .gt_super {
  font-size: 65%;
}

#uvwbajtdwn .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#uvwbajtdwn .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#uvwbajtdwn .gt_indent_1 {
  text-indent: 5px;
}

#uvwbajtdwn .gt_indent_2 {
  text-indent: 10px;
}

#uvwbajtdwn .gt_indent_3 {
  text-indent: 15px;
}

#uvwbajtdwn .gt_indent_4 {
  text-indent: 20px;
}

#uvwbajtdwn .gt_indent_5 {
  text-indent: 25px;
}

#uvwbajtdwn .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#uvwbajtdwn div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<thead>
<tr class="gt_heading header">
<th colspan="3" class="gt_heading gt_title gt_font_normal gt_bottom_border">Number of Posts by Chamber and Party</th>
</tr>
<tr class="gt_col_headings even">
<th id="a::stub" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col"></th>
<th id="democrat" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">democrat</th>
<th id="republican" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">republican</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td id="stub_1_1" class="gt_row gt_left gt_stub" data-quarto-table-cell-role="th" scope="row">house</td>
<td class="gt_row gt_right" headers="stub_1_1 democrat">89808</td>
<td class="gt_row gt_right" headers="stub_1_1 republican">167004</td>
</tr>
<tr class="even">
<td id="stub_1_2" class="gt_row gt_left gt_stub" data-quarto-table-cell-role="th" scope="row">senate</td>
<td class="gt_row gt_right" headers="stub_1_2 democrat">37890</td>
<td class="gt_row gt_right" headers="stub_1_2 republican">39904</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Next, the distribution of post lengths is examined. To limit the influence of outliers, the top one percent of longest posts are excluded:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/unnamed-chunk-2-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2"><img src="index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>The dataset also allows identifying the most active members. The figure below displays the top five posters for each chamber–party combination:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/unnamed-chunk-3-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-3"><img src="index_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
<p>Finally, the most frequent words used by each party are explored. After tokenizing posts, removing stopwords, and excluding a small set of custom stop terms, the top twenty terms per party are identified:</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="index_files/figure-html/unnamed-chunk-4-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-4"><img src="index_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a></p>
</figure>
</div>
</div>
</div>
</section>
<section id="model-specification" class="level2">
<h2 class="anchored" data-anchor-id="model-specification">Model specification</h2>
<section id="tokenization-and-feature-extraction" class="level3">
<h3 class="anchored" data-anchor-id="tokenization-and-feature-extraction">Tokenization and feature extraction</h3>
<p>The input pipeline leverages a pre-trained Transformer model, specifically <code>all-MiniLM-L6-v2</code>, to generate contextualized semantic features. Unlike traditional pipelines that feed token IDs directly to the classifier, this architecture utilizes the Transformer as a frozen feature extractor.</p>
<p>Raw text is tokenized and padded to a fixed sequence length <span class="math inline">T=128</span>. Let <span class="math inline">\mathbf{t}</span> be the sequence of token identifiers. These are passed through the quantized (4-bit) Transformer model <span class="math inline">\mathcal{F}</span> to yield a sequence of dense vectors:</p>
<p><span id="eq-transformer-out"><span class="math display">
\mathbf{X} = \mathcal{F}(\mathbf{t}) \in \mathbb{R}^{T \times D},
\tag{1}</span></span></p>
<p>where <span class="math inline">D</span> is the embedding dimension (inferred from the Transformer output, typically 384 for MiniLM). Crucially, a stop-gradient operation is applied to <span class="math inline">\mathbf{X}</span>:</p>
<p><span id="eq-stop-grad"><span class="math display">
\mathbf{X}_{\text{fixed}} = \text{StopGradient}(\mathbf{X}),
\tag{2}</span></span></p>
<p>ensuring that gradients are not backpropagated into the Transformer layers, treating the embeddings as static inputs to the downstream LSTM.</p>
</section>
<section id="bidirectional-lstm-encoder" class="level3">
<h3 class="anchored" data-anchor-id="bidirectional-lstm-encoder">Bidirectional LSTM encoder</h3>
<p>A custom implementation of a Bidirectional LSTM is employed to model the temporal dependencies within the sequence of embeddings <span class="math inline">\mathbf{X}_{\text{fixed}}</span>.</p>
<p>The architecture consists of two independent LSTM layers: a forward pass (<span class="math inline">\overrightarrow{\text{LSTM}}</span>) and a backward pass (<span class="math inline">\overleftarrow{\text{LSTM}}</span>). For a single direction, the state update at timestep <span class="math inline">t</span>, given input <span class="math inline">\mathbf{x}_t</span> and previous hidden state <span class="math inline">\mathbf{h}_{t-1}</span>, is governed by the standard gate equations:</p>
<p><span id="eq-lstm-gates"><span class="math display">
\begin{align}
\mathbf{i}_t &amp;= \sigma(W_i\mathbf{x}_t + U_i\mathbf{h}_{t-1} + \mathbf{b}_i) \\
\mathbf{f}_t &amp;= \sigma(W_f\mathbf{x}_t + U_f\mathbf{h}_{t-1} + \mathbf{b}_f) \\
\mathbf{o}_t &amp;= \sigma(W_o\mathbf{x}_t + U_o\mathbf{h}_{t-1} + \mathbf{b}_o) \\
\mathbf{g}_t &amp;= \tanh(W_g\mathbf{x}_t + U_g\mathbf{h}_{t-1} + \mathbf{b}_g) \\
\mathbf{c}_t &amp;= \mathbf{f}_t \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \mathbf{g}_t \\
\mathbf{h}_t &amp;= \mathbf{o}_t \odot \tanh(\mathbf{c}_t)
\end{align}
\tag{3}</span></span></p>
<p>where <span class="math inline">\sigma</span> is the sigmoid function and <span class="math inline">\odot</span> is the Hadamard product. The hidden state dimension is <span class="math inline">H=128</span>. The backward LSTM processes the sequence in reverse order. The final representation at each timestep is the concatenation of both directional states:</p>
<p><span id="eq-bilstm-out"><span class="math display">
\mathbf{h}_t = [\overrightarrow{\mathbf{h}}_t ; \overleftarrow{\mathbf{h}}_t] \in \mathbb{R}^{2H}.
\tag{4}</span></span></p>
</section>
<section id="masked-mean-pooling" class="level3">
<h3 class="anchored" data-anchor-id="masked-mean-pooling">Masked mean pooling</h3>
<p>To handle the padding artifacts present in the fixed-length sequences, a masked mean pooling operation is applied. Let <span class="math inline">\mathbf{m} \in \{0, 1\}^T</span> be the attention mask where <span class="math inline">1</span> denotes a valid token. The fixed-size sentence representation <span class="math inline">\mathbf{z}</span> is computed as:</p>
<p><span id="eq-masked-pool"><span class="math display">
\mathbf{z} = \frac{\sum_{t=1}^{T} m_t \mathbf{h}_t}{\sum_{t=1}^{T} m_t + \epsilon} \in \mathbb{R}^{2H},
\tag{5}</span></span></p>
<p>where <span class="math inline">\epsilon = 10^{-6}</span> ensures numerical stability. This collapses the temporal dimension, resulting in a single vector capturing the global context of the post.</p>
</section>
<section id="classification-head" class="level3">
<h3 class="anchored" data-anchor-id="classification-head">Classification head</h3>
<p>The pooled vector <span class="math inline">\mathbf{z}</span> serves as the input to the classification head. Regularization is applied via Dropout with probability <span class="math inline">p=0.1</span>:</p>
<p><span id="eq-dropout"><span class="math display">
\tilde{\mathbf{z}} = \text{Dropout}(\mathbf{z}).
\tag{6}</span></span></p>
<p>A linear projection layer maps the features to the unnormalized logits for the two classes:</p>
<p><span id="eq-linear-head"><span class="math display">
\mathbf{o} = W_{out}\tilde{\mathbf{z}} + \mathbf{b}_{out} \in \mathbb{R}^2.
\tag{7}</span></span></p>
<p>The predicted class <span class="math inline">\hat{y}</span> is derived via the argmax of the logits.</p>
</section>
<section id="training-objective" class="level3">
<h3 class="anchored" data-anchor-id="training-objective">Training objective</h3>
<p>The model is trained using the Cross-Entropy loss function. For a batch of <span class="math inline">N</span> samples, the objective is to minimize:</p>
<p><span id="eq-jross-entropy"><span class="math display">
\mathcal{L} = \frac{1}{N} \sum_{i=1}^{N} \text{CrossEntropy}(\mathbf{o}^{(i)}, y^{(i)}).
\tag{8}</span></span></p>
<p>Optimization is performed using the <strong>Adam</strong> optimizer with a learning rate <span class="math inline">\eta = 10^{-3}</span>. The training step, including the loss calculation and gradient update, is Just-In-Time (JIT) compiled into a comprehensive computation graph using <code>mx.compile</code> to maximize execution speed.</p>
</section>
<section id="computational-considerations" class="level3">
<h3 class="anchored" data-anchor-id="computational-considerations">Computational considerations</h3>
<p>The implementation is optimized for Apple Silicon using the MLX framework. Several specific strategies are employed for efficiency:</p>
<ol type="1">
<li><strong>Lazy Evaluation &amp; Materialization:</strong> MLX uses lazy evaluation. To prevent the computation graph from growing indefinitely during the iterative data loading process, <code>mx.eval</code> is explicitly called on batch inputs and loss values to force materialization.</li>
<li><strong>Quantized Feature Extraction:</strong> The embedding model (<code>all-MiniLM-L6-v2</code>) utilizes 4-bit quantization, significantly reducing memory bandwidth requirements during the feature extraction phase.</li>
<li><strong>Precision:</strong> The embeddings are cast to <code>float16</code> (<code>mx.float16</code>) before entering the LSTM, halving the memory footprint of the batch tensor compared to <code>float32</code> and leveraging the hardware’s native half-precision performance.</li>
</ol>
</section>
</section>
<section id="data-pipeline" class="level2">
<h2 class="anchored" data-anchor-id="data-pipeline">Data Pipeline</h2>
<p>The pipeline proceeds as:</p>
<ul>
<li>Read the cleaned CSV (<code>congress_complete.csv</code>) and keep the relevant columns (<code>post</code> and <code>party</code>).</li>
<li>Drop rows with missing text or party labels.</li>
<li>Normalize party strings and map them to binary labels (Democrat = 0, Republican = 1), discarding any other labels.</li>
<li>Perform a stratified train/validation/test split with proportions 80/10/10 using a fixed random seed.</li>
<li>During training and evaluation, tokenize <strong>on the fly</strong> per batch and pad/truncate to a fixed length (T=128).</li>
<li>For each minibatch, pass token IDs and attention masks through a <strong>frozen, quantized MiniLM encoder</strong> to obtain contextual token embeddings. Gradients are stopped at this stage, so only the downstream BiLSTM is trained.</li>
<li>Cast embeddings to <code>float16</code> to reduce memory use; keep attention masks to zero out padding tokens before recurrence and for masked mean pooling.</li>
</ul>
<p>This design avoids storing large precomputed embedding tensors in RAM. Instead, embeddings are computed batch-wise and materialized with <code>mx.eval</code> so MLX graphs do not accumulate across iterations.</p>
<section id="training-loop" class="level3">
<h3 class="anchored" data-anchor-id="training-loop">Training Loop</h3>
<p>The training routine runs for 10 epochs with a fixed batch size of 64. In each epoch:</p>
<ul>
<li><p>Set the model to training mode.</p></li>
<li><p>Iterate over batches produced by <code>batch_iterate_text(..., drop_last=True)</code> so every training step has identical shape (required for <code>mx.compile</code>).</p></li>
<li><p>For each batch:</p>
<ul>
<li>Compute logits with the BiLSTM classifier.</li>
<li>Compute mean cross-entropy loss.</li>
<li>Backpropagate to obtain gradients for the BiLSTM parameters.</li>
<li>Update parameters using the <strong>Adam</strong> optimizer with learning rate (10^{-3}).</li>
</ul></li>
<li><p>After each epoch, switch to evaluation mode and compute validation loss and accuracy over the full validation split (<code>drop_last=False</code>).</p></li>
</ul>
<p>The training step is JIT-compiled via <code>mx.compile</code> for speed. There is no checkpointing or best-model reload in the current code; the reported test results come from the final epoch’s parameters.</p>
</section>
<section id="implementation-in-code" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-code">Implementation in Code</h3>
<p>The biLStM model has been in apples mlx framework to enable a bare metal run of the model on apple silicon hardware. The implementation has ben performd on top of the mlx framework provided <code>nn.Module</code> function.</p>
<p>for that a LSTM cell has been set up as follows</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LSTMCell(nn.Module):</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.xh_to_gates <span class="op">=</span> nn.Linear(input_size <span class="op">+</span> hidden_size, <span class="dv">4</span> <span class="op">*</span> hidden_size)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x_t, state):</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        h_prev, c_prev <span class="op">=</span> state</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        xh <span class="op">=</span> mx.concatenate([x_t, h_prev], axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        gates <span class="op">=</span> <span class="va">self</span>.xh_to_gates(xh)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        i, f, o, g <span class="op">=</span> mx.split(gates, <span class="dv">4</span>, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> mx.sigmoid(i)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> mx.sigmoid(f)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        o <span class="op">=</span> mx.sigmoid(o)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        g <span class="op">=</span> mx.tanh(g)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        c_t <span class="op">=</span> f <span class="op">*</span> c_prev <span class="op">+</span> i <span class="op">*</span> g</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        h_t <span class="op">=</span> o <span class="op">*</span> mx.tanh(c_t)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> h_t, c_t</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Used in a single lstm model as follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LSTM(nn.Module):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hidden_size <span class="op">=</span> hidden_size</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cell <span class="op">=</span> LSTMCell(input_size, hidden_size)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        B, T, _ <span class="op">=</span> x.shape</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        h <span class="op">=</span> mx.zeros((B, <span class="va">self</span>.hidden_size), dtype<span class="op">=</span>mx.float32)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> mx.zeros((B, <span class="va">self</span>.hidden_size), dtype<span class="op">=</span>mx.float32)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> []</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            h, c <span class="op">=</span> <span class="va">self</span>.cell(x[:, t, :], (h, c))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            outputs.append(h)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mx.stack(outputs, axis<span class="op">=</span><span class="dv">1</span>), (h, c)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And finally the bidirectional lstm is set up along the text classification:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BiLSTM(nn.Module):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, input_size, hidden_size):</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fwd <span class="op">=</span> LSTM(input_size, hidden_size)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bwd <span class="op">=</span> LSTM(input_size, hidden_size)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x):</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        B, T, _ <span class="op">=</span> x.shape</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        fwd_out, _ <span class="op">=</span> <span class="va">self</span>.fwd(x)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        rev_idx <span class="op">=</span> mx.arange(T <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, dtype<span class="op">=</span>mx.int32)</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        x_rev <span class="op">=</span> mx.take(x, rev_idx, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        bwd_out_rev, _ <span class="op">=</span> <span class="va">self</span>.bwd(x_rev)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        bwd_out <span class="op">=</span> mx.take(bwd_out_rev, rev_idx, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mx.concatenate([fwd_out, bwd_out], axis<span class="op">=-</span><span class="dv">1</span>)  <span class="co"># (B, T, 2H)</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> BiLSTMTextClassifier(nn.Module):</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, embedding_dim, hidden_size, num_classes, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bilstm <span class="op">=</span> BiLSTM(embedding_dim, hidden_size)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.head <span class="op">=</span> nn.Linear(<span class="dv">2</span> <span class="op">*</span> hidden_size, num_classes)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pool(<span class="va">self</span>, seq_out, mask):</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        mask_f <span class="op">=</span> mask.astype(mx.float32)[..., <span class="va">None</span>]</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>        summed <span class="op">=</span> mx.<span class="bu">sum</span>(seq_out <span class="op">*</span> mask_f, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>        denom <span class="op">=</span> mx.maximum(mx.<span class="bu">sum</span>(mask_f, axis<span class="op">=</span><span class="dv">1</span>), <span class="fl">1e-6</span>)</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> summed <span class="op">/</span> denom</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, x, mask):</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero out padding before recurrence</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">*</span> mask.astype(mx.float32)[..., <span class="va">None</span>]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        seq_out <span class="op">=</span> <span class="va">self</span>.bilstm(x)</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        pooled <span class="op">=</span> <span class="va">self</span>.pool(seq_out, mask)</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        pooled <span class="op">=</span> <span class="va">self</span>.dropout(pooled)</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.head(pooled)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To use the framework to it’s full poterntial the model its is compiled</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="at">@partial</span>(mx.<span class="bu">compile</span>, inputs<span class="op">=</span>state, outputs<span class="op">=</span>state)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> step(Xb, yb, Mb):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    loss, grads <span class="op">=</span> loss_and_grad(model, Xb, yb, Mb)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    optimizer.update(model, grads)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> loss</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The description of the loss function is omitted but can be found in the complete code in the repository</p>
</section>
</section>
<section id="sec-nbb" class="level2">
<h2 class="anchored" data-anchor-id="sec-nbb">Naive Bayes Baseline</h2>
<p>As a classical probabilistic benchmark, a Naive Bayes classifier is employed alongside the neural sequence model. To ensure comparability, all preprocessing steps prior to feature extraction—data cleaning, label normalization, and the exact train/validation/test split—are identical to those used for the BiLSTM classifier.</p>
<section id="model-description" class="level3">
<h3 class="anchored" data-anchor-id="model-description">Model description</h3>
<p>In contrast to the sequence-based neural architecture, the Naive Bayes model operates on a sparse bag-of-ngrams representation of the text. Each document <span class="math inline">x</span> is mapped to a TF–IDF feature vector <span id="eq-eq-tfidf"><span class="math display">
\mathbf{f}(x) = (f_1, f_2, \ldots, f_d),
\tag{9}</span></span></p>
<p>where each <span class="math inline">f_j</span> reflects the TF–IDF weight of term <span class="math inline">j</span> after vocabulary truncation and filtering. The vectorizer uses standard preprocessing settings for text classification:</p>
<ul>
<li>lowercasing</li>
<li>English stop-word removal</li>
<li>unigram and bigram features <span class="math inline">(1,2)</span></li>
<li>a maximum feature cap of <span class="math inline">d = 50{,}000</span></li>
<li>a minimum document frequency of <span class="math inline">2</span></li>
</ul>
<p>The classifier itself is a Multinomial Naive Bayes model, which assumes conditional independence of features given a class label <span class="math inline">y\in{0,1}</span>. Under this assumption, the likelihood of observing the feature vector <span class="math inline">\mathbf{f}(x)</span> given class <span class="math inline">k</span> factorizes as</p>
<p><span id="eq-nb-likelihood"><span class="math display">
p(\mathbf{f}(x)\mid y=k)
;\propto;
\prod_{j=1}^{d}
\theta_{kj}^{, f_j(x)},
\tag{10}</span></span></p>
<p>where <span class="math inline">\theta_{kj}</span> are class-conditional feature probabilities estimated from the training set. Bayes’ rule then yields the posterior</p>
<p><span id="eq-nb-posterior"><span class="math display">
p(y=k \mid x)
;\propto;
p(y=k)\prod_{j=1}^{d}\theta_{kj}^{, f_j(x)},
\tag{11}</span></span></p>
<p>and prediction is made via</p>
<p><span id="eq-nb-prediction"><span class="math display">
\hat{y} = \arg\max_{k\in{0,1}} p(y=k\mid x).
\tag{12}</span></span></p>
<p>Although the multinomial model is derived for count data, it is widely used with TF–IDF features and remains a strong linear baseline in high-dimensional text classification.</p>
</section>
</section>
<section id="empirical-assessments" class="level2">
<h2 class="anchored" data-anchor-id="empirical-assessments">Empirical Assessments</h2>
<p>This section reports the empirical performance of the two main classifiers: the BiLSTM sequence model and the Naive Bayes baseline.</p>
<section id="bilstm" class="level3">
<h3 class="anchored" data-anchor-id="bilstm">BiLSTM</h3>
<section id="headline-results" class="level4">
<h4 class="anchored" data-anchor-id="headline-results">Headline results</h4>
<p>On the held-out test partition, the BiLSTM achieves:</p>
<p><span class="math display">
\text{Test loss} = 0.5229,\qquad
\text{Test accuracy} = 0.7952.
</span>{#ewq-bilstm-acc}</p>
<p>Validation- and test-set performance are closely aligned, suggesting stable generalization without pronounced overfitting.</p>
</section>
<section id="class-wise-metrics" class="level4">
<h4 class="anchored" data-anchor-id="class-wise-metrics">Class-wise metrics</h4>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>BiLSTM: test-set classification report.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Class</th>
<th style="text-align: right;">Precision</th>
<th style="text-align: right;">Recall</th>
<th style="text-align: right;">F1</th>
<th style="text-align: right;">Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">0.7621</td>
<td style="text-align: right;">0.6748</td>
<td style="text-align: right;">0.7158</td>
<td style="text-align: right;">12729</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">0.8121</td>
<td style="text-align: right;">0.8697</td>
<td style="text-align: right;">0.8399</td>
<td style="text-align: right;">20573</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Accuracy</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.7952</td>
<td style="text-align: right;">33302</td>
</tr>
<tr class="even">
<td style="text-align: left;">Macro avg</td>
<td style="text-align: right;">0.7871</td>
<td style="text-align: right;">0.7723</td>
<td style="text-align: right;">0.7779</td>
<td style="text-align: right;">33302</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Weighted avg</td>
<td style="text-align: right;">0.7930</td>
<td style="text-align: right;">0.7952</td>
<td style="text-align: right;">0.7925</td>
<td style="text-align: right;">33302</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Performance is systematically stronger for class 1, which is also the majority class in the data and therefore this behaviour is somewhat expected. The macro-averaged <span class="math inline">F_1</span> is slightly lower than the weighted average, reflecting the impact of class imbalance on aggregate metrics.</p>
</section>
<section id="confusion-matrix-and-derived-rates" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix-and-derived-rates">Confusion matrix and derived rates</h4>
<p>The test-set confusion matrix for the BiLSTM is:</p>
<p><span id="eq-bilstm-conf-mat"><span class="math display">
\mathbf{C} =
\begin{pmatrix}
8590 &amp; 4139 \\
2681 &amp; 17892
\end{pmatrix}.
\tag{13}</span></span></p>
<p>Treating class 1 as the positive class, the following quantities are obtained:</p>
<p><span id="eq-bilstm-derived-metrics"><span class="math display">
\begin{aligned}
\text{TPR (recall$_1$)} &amp;= \frac{17892}{17892+2681}=0.8697, \\
\text{TNR (specificity)} &amp;= \frac{8590}{8590+4139}=0.6748, \\
\text{FPR} &amp;= \frac{4139}{8590+4139}=0.3252, \\
\text{FNR} &amp;= \frac{2681}{17892+2681}=0.1303, \\
\text{Balanced accuracy} &amp;= \frac{0.8697+0.6748}{2}=0.7723, \\
\text{MCC} &amp;= 0.5592.
\end{aligned}
\tag{14}</span></span></p>
</section>
<section id="error-profile" class="level4">
<h4 class="anchored" data-anchor-id="error-profile">Error profile</h4>
<p>The confusion matrix indicates two main error patterns:</p>
<ul>
<li><p><strong>Class 0 → Class 1</strong>: A comparatively large number of false positives (items from class 0 predicted as class 1) likely arises from shared lexical or stylistic features between the two parties, amplified by class imbalance which then leads to a bigger set of possible patterns are beeing labeled as class 1.</p></li>
<li><p><strong>Class 1 → Class 0</strong>: Fewer false negatives for class 1, which may correspond to more moderate or cross-partisan language that is less prototypical of the majority class.</p></li>
</ul>
<p>The false-positive rate is roughly twice the false-negative rate, implying that the classifier tends to err toward predicting class 1. In applications with asymmetric error costs, this tendency could be counteracted by threshold adjustment, class-weighted loss functions, or post-hoc calibration.</p>
<p>The distribution of posts lengths does not have an impact on the error profile as throughout the dataset the post length distribution is similar across classes as shown in <a href="#sec-eda" class="quarto-xref">Section&nbsp;3</a> .</p>
</section>
</section>
<section id="qualitative-analysis" class="level3">
<h3 class="anchored" data-anchor-id="qualitative-analysis">Qualitative Analysis</h3>
<p>To show the qualitative implications of the model a sample of posts is classified here.</p>
<section id="single-words" class="level4">
<h4 class="anchored" data-anchor-id="single-words">Single words</h4>
<p>The model is given a list of the most comon english words and their predicted probabilities for each class. The results are visualized in <a href="#fig-word-bias" class="quarto-xref">Figure&nbsp;2</a>, which plots the margin (p_dem − p_repub) for each word against its rank in the sorted list. Points are colored by margin and sized by confidence (maximum predicted probability). The twenty most extreme words on either end of the spectrum are labeled.</p>
<div id="cell-fig-word-bias" class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-word-bias" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-word-bias-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="index_files/figure-html/fig-word-bias-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-5" title="Figure&nbsp;2: Model bias on common words"><img src="index_files/figure-html/fig-word-bias-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-word-bias-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Model bias on common words
</figcaption>
</figure>
</div>
</div>
</div>
<p>As Figure <a href="#fig-word-bias" class="quarto-xref">Figure&nbsp;2</a> indicates, the classifier shows pronounced partisan leanings even when evaluated on isolated tokens.</p>
<p>A natural next step is to test whether this behavior is stable over time. In particular, one could examine whether applying the model to contemporary Republican and Democratic posts changes its performance, given well-documented shifts in political communication and issue framing over recent years.</p>
</section>
</section>
<section id="naive-bayes-baseline" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes-baseline">Naive Bayes Baseline</h3>
<section id="headline-results-1" class="level4">
<h4 class="anchored" data-anchor-id="headline-results-1">Headline results</h4>
<p>As a bag-of-words baseline, the Naive Bayes classifier attains the following accuracy on the test set:</p>
<p><span id="eq-nb-acc"><span class="math display">
\text{Test accuracy} = 0.7843
\tag{15}</span></span></p>
<p>Given its simplicity and lack of contextual or sequential modeling, this level of performance is comparatively strong, but still below that of the BiLSTM.</p>
</section>
<section id="class-wise-metrics-1" class="level4">
<h4 class="anchored" data-anchor-id="class-wise-metrics-1">Class-wise metrics</h4>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Naive Bayes: test-set classification report.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Class</th>
<th style="text-align: right;">Precision</th>
<th style="text-align: right;">Recall</th>
<th style="text-align: right;">F1</th>
<th style="text-align: right;">Support</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: right;">0.7698</td>
<td style="text-align: right;">0.6214</td>
<td style="text-align: right;">0.6877</td>
<td style="text-align: right;">12729</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: right;">0.7907</td>
<td style="text-align: right;">0.8850</td>
<td style="text-align: right;">0.8352</td>
<td style="text-align: right;">20573</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Accuracy</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">0.7843</td>
<td style="text-align: right;">33302</td>
</tr>
<tr class="even">
<td style="text-align: left;">Macro avg</td>
<td style="text-align: right;">0.7803</td>
<td style="text-align: right;">0.7532</td>
<td style="text-align: right;">0.7615</td>
<td style="text-align: right;">33302</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Weighted avg</td>
<td style="text-align: right;">0.7827</td>
<td style="text-align: right;">0.7843</td>
<td style="text-align: right;">0.7788</td>
<td style="text-align: right;">33302</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>As with the BiLSTM, performance is higher for class 1 than for class 0. Precision and recall for class 1 are clearly stronger, indicating a tendency to assign documents to the majority class and to capture its lexical cues more reliably.</p>
</section>
<section id="confusion-matrix-and-error-profile" class="level4">
<h4 class="anchored" data-anchor-id="confusion-matrix-and-error-profile">Confusion matrix and error profile</h4>
<p>The corresponding test-set confusion matrix for the Naive Bayes classifier is</p>
<p><span id="eq-nb-conf-mat"><span class="math display">
\begin{pmatrix}
9599 &amp; 3171 \\
2025 &amp; 18666
\end{pmatrix}.
\tag{16}</span></span></p>
<p>False positives for class 1 (3171 cases) are moderately more frequent than in the BiLSTM. Overall, the baseline captures strong lexical signals at low computational cost but offers less balanced performance across classes than the sequence model.</p>
</section>
</section>
<section id="comparative-perspective" class="level3">
<h3 class="anchored" data-anchor-id="comparative-perspective">Comparative perspective</h3>
<p>To assess whether the BiLSTM improves upon the Naive Bayes baseline in a systematic way, a side-by-side comparison of key metrics is provided in <a href="#tbl-comp" class="quarto-xref">Table&nbsp;1</a>. The BiLSTM offers modest gains in overall accuracy and more favorable error balance across classes, while the Naive Bayes classifier remains a competitive and interpretable lexical baseline.</p>
<div class="cell">
<div id="tbl-comp" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Model Comparison
</figcaption>
<div aria-describedby="tbl-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div id="pjprzgbdoq" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#pjprzgbdoq table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#pjprzgbdoq thead, #pjprzgbdoq tbody, #pjprzgbdoq tfoot, #pjprzgbdoq tr, #pjprzgbdoq td, #pjprzgbdoq th {
  border-style: none;
}

#pjprzgbdoq p {
  margin: 0;
  padding: 0;
}

#pjprzgbdoq .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#pjprzgbdoq .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#pjprzgbdoq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#pjprzgbdoq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#pjprzgbdoq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pjprzgbdoq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pjprzgbdoq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#pjprzgbdoq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#pjprzgbdoq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#pjprzgbdoq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#pjprzgbdoq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#pjprzgbdoq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#pjprzgbdoq .gt_spanner_row {
  border-bottom-style: hidden;
}

#pjprzgbdoq .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#pjprzgbdoq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#pjprzgbdoq .gt_from_md > :first-child {
  margin-top: 0;
}

#pjprzgbdoq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#pjprzgbdoq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#pjprzgbdoq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#pjprzgbdoq .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#pjprzgbdoq .gt_row_group_first td {
  border-top-width: 2px;
}

#pjprzgbdoq .gt_row_group_first th {
  border-top-width: 2px;
}

#pjprzgbdoq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pjprzgbdoq .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#pjprzgbdoq .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#pjprzgbdoq .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pjprzgbdoq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#pjprzgbdoq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#pjprzgbdoq .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#pjprzgbdoq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#pjprzgbdoq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#pjprzgbdoq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pjprzgbdoq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#pjprzgbdoq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#pjprzgbdoq .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#pjprzgbdoq .gt_left {
  text-align: left;
}

#pjprzgbdoq .gt_center {
  text-align: center;
}

#pjprzgbdoq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#pjprzgbdoq .gt_font_normal {
  font-weight: normal;
}

#pjprzgbdoq .gt_font_bold {
  font-weight: bold;
}

#pjprzgbdoq .gt_font_italic {
  font-style: italic;
}

#pjprzgbdoq .gt_super {
  font-size: 65%;
}

#pjprzgbdoq .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#pjprzgbdoq .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#pjprzgbdoq .gt_indent_1 {
  text-indent: 5px;
}

#pjprzgbdoq .gt_indent_2 {
  text-indent: 10px;
}

#pjprzgbdoq .gt_indent_3 {
  text-indent: 15px;
}

#pjprzgbdoq .gt_indent_4 {
  text-indent: 20px;
}

#pjprzgbdoq .gt_indent_5 {
  text-indent: 25px;
}

#pjprzgbdoq .katex-display {
  display: inline-flex !important;
  margin-bottom: 0.75em !important;
}

#pjprzgbdoq div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {
  height: 0px !important;
}
</style>

<table class="gt_table do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
<colgroup>
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="gt_heading header">
<th colspan="9" class="gt_heading gt_title gt_font_normal">Model Comparison</th>
</tr>
<tr class="gt_heading even">
<th colspan="9" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border">Cells highlighted indicate the winning model for that specific metric</th>
</tr>
<tr class="gt_col_headings gt_spanner_row header">
<th rowspan="2" id="Class" class="gt_col_heading gt_columns_bottom_border gt_left" data-quarto-table-cell-role="th" scope="col">Class</th>
<th colspan="4" id="BiLSTM" class="gt_center gt_columns_top_border gt_column_spanner_outer" data-quarto-table-cell-role="th" scope="colgroup"><div class="gt_column_spanner">
BiLSTM
</div></th>
<th colspan="4" id="Naive Bayes" class="gt_center gt_columns_top_border gt_column_spanner_outer" data-quarto-table-cell-role="th" scope="colgroup"><div class="gt_column_spanner">
Naive Bayes
</div></th>
</tr>
<tr class="gt_col_headings even">
<th id="Precision_BiLSTM" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Precision</th>
<th id="Recall_BiLSTM" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Recall</th>
<th id="F1_BiLSTM" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1</th>
<th id="Support_BiLSTM" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Support</th>
<th id="Precision_NB" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Precision</th>
<th id="Recall_NB" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Recall</th>
<th id="F1_NB" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">F1</th>
<th id="Support_NB" class="gt_col_heading gt_columns_bottom_border gt_right" data-quarto-table-cell-role="th" scope="col">Support</th>
</tr>
</thead>
<tbody class="gt_table_body">
<tr class="odd">
<td class="gt_row gt_left" headers="Class">0</td>
<td class="gt_row gt_right" headers="Precision_BiLSTM">0.7621</td>
<td class="gt_row gt_right" headers="Recall_BiLSTM" style="background-color: #D4F0D4">0.6748</td>
<td class="gt_row gt_right" headers="F1_BiLSTM" style="background-color: #D4F0D4">0.7158</td>
<td class="gt_row gt_right" headers="Support_BiLSTM" style="border-right-width: 2px; border-right-style: solid; border-right-color: #d3d3d3">12729</td>
<td class="gt_row gt_right" headers="Precision_NB" style="background-color: #D4F0D4">0.7698</td>
<td class="gt_row gt_right" headers="Recall_NB">0.6214</td>
<td class="gt_row gt_right" headers="F1_NB">0.6877</td>
<td class="gt_row gt_right" headers="Support_NB">12729</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Class">1</td>
<td class="gt_row gt_right" headers="Precision_BiLSTM" style="background-color: #D4F0D4">0.8121</td>
<td class="gt_row gt_right" headers="Recall_BiLSTM">0.8697</td>
<td class="gt_row gt_right" headers="F1_BiLSTM" style="background-color: #D4F0D4">0.8399</td>
<td class="gt_row gt_right" headers="Support_BiLSTM" style="border-right-width: 2px; border-right-style: solid; border-right-color: #d3d3d3">20573</td>
<td class="gt_row gt_right" headers="Precision_NB">0.7907</td>
<td class="gt_row gt_right" headers="Recall_NB" style="background-color: #D4F0D4">0.8850</td>
<td class="gt_row gt_right" headers="F1_NB">0.8352</td>
<td class="gt_row gt_right" headers="Support_NB">20573</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Class">Accuracy</td>
<td class="gt_row gt_right" headers="Precision_BiLSTM">-</td>
<td class="gt_row gt_right" headers="Recall_BiLSTM">-</td>
<td class="gt_row gt_right" headers="F1_BiLSTM" style="background-color: #D4F0D4">0.7952</td>
<td class="gt_row gt_right" headers="Support_BiLSTM" style="border-right-width: 2px; border-right-style: solid; border-right-color: #d3d3d3">33302</td>
<td class="gt_row gt_right" headers="Precision_NB">-</td>
<td class="gt_row gt_right" headers="Recall_NB">-</td>
<td class="gt_row gt_right" headers="F1_NB">0.7843</td>
<td class="gt_row gt_right" headers="Support_NB">33302</td>
</tr>
<tr class="even">
<td class="gt_row gt_left" headers="Class">Macro avg</td>
<td class="gt_row gt_right" headers="Precision_BiLSTM" style="background-color: #D4F0D4">0.7871</td>
<td class="gt_row gt_right" headers="Recall_BiLSTM" style="background-color: #D4F0D4">0.7723</td>
<td class="gt_row gt_right" headers="F1_BiLSTM" style="background-color: #D4F0D4">0.7779</td>
<td class="gt_row gt_right" headers="Support_BiLSTM" style="border-right-width: 2px; border-right-style: solid; border-right-color: #d3d3d3">33302</td>
<td class="gt_row gt_right" headers="Precision_NB">0.7803</td>
<td class="gt_row gt_right" headers="Recall_NB">0.7532</td>
<td class="gt_row gt_right" headers="F1_NB">0.7615</td>
<td class="gt_row gt_right" headers="Support_NB">33302</td>
</tr>
<tr class="odd">
<td class="gt_row gt_left" headers="Class">Weighted avg</td>
<td class="gt_row gt_right" headers="Precision_BiLSTM" style="background-color: #D4F0D4">0.7930</td>
<td class="gt_row gt_right" headers="Recall_BiLSTM" style="background-color: #D4F0D4">0.7952</td>
<td class="gt_row gt_right" headers="F1_BiLSTM" style="background-color: #D4F0D4">0.7925</td>
<td class="gt_row gt_right" headers="Support_BiLSTM" style="border-right-width: 2px; border-right-style: solid; border-right-color: #d3d3d3">33302</td>
<td class="gt_row gt_right" headers="Precision_NB">0.7827</td>
<td class="gt_row gt_right" headers="Recall_NB">0.7843</td>
<td class="gt_row gt_right" headers="F1_NB">0.7788</td>
<td class="gt_row gt_right" headers="Support_NB">33302</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
</section>
</section>
<section id="limitations-and-possible-extensions" class="level2">
<h2 class="anchored" data-anchor-id="limitations-and-possible-extensions">Limitations and possible extensions</h2>
<section id="limitations" class="level3">
<h3 class="anchored" data-anchor-id="limitations">Limitations</h3>
<p>The primary constraint of the current model is its reliance on frozen feature extraction. Because the Transformer <span class="math inline">\mathcal{F}</span> functions purely as a static input generator with stop-gradient operations, the embedding space is unable to adapt to the specific political vernacular of the congressional dataset during backpropagation. This lack of domain adaptation is compounded by precision limitations; the utilization of a 4-bit quantized Transformer and the subsequent casting of embeddings to <code>float16</code> introduces quantization noise that, while efficient, may discard subtle semantic distinctions found in full-precision representations. Furthermore, the architecture exhibits potential redundancy by stacking a BiLSTM on top of a powerful contextual encoder. Since the MiniLM Transformer already captures long-range dependencies via self-attention, the addition of recurrence introduces a sequential bottleneck without necessarily increasing modeling capacity significantly. Finally, the masked mean pooling strategy treats all valid tokens as equally important, a simplification that risks diluting strong, localized discriminative signals within longer posts.</p>
</section>
<section id="extensions" class="level3">
<h3 class="anchored" data-anchor-id="extensions">Extensions</h3>
<p>To address these limitations, several architectural and training modifications could be implemented. A significant performance boost could be achieved through end-to-end fine-tuning, where the Transformer layers are unfrozen to allow gradients to flow through <span class="math inline">\mathcal{F}</span>. To manage the memory overhead of this approach on Apple Silicon, techniques such as Low-Rank Adaptation (LoRA) could be employed to fine-tune the encoder efficiently. Alternatively, efficiency could be prioritized by moving to a Transformer-only architecture, removing the BiLSTM layer entirely and projecting the Transformer’s <code>[CLS]</code> token directly to the classification head; this would simplify the compute graph and eliminate the sequential dependency. Regarding feature aggregation, replacing mean pooling with a learnable attention mechanism would allow the model to weigh informative keywords more heavily than neutral connective text. Finally, while the current model truncates inputs at 128 tokens, implementing a sliding window approach or utilizing the full 512-token capacity of MiniLM would better capture tail-end context in lengthy statements.</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The implemented pipeline offers a computationally efficient neural baseline for binary party attribution in political texts. By combining subword token IDs with frozen embeddings and a BiLSTM encoder, the system captures sequential patterns and achieves solid test performance. Evaluation reveals a mild bias toward predicting the majority class, visible in an elevated false-positive rate for class <span class="math inline">0</span>.</p>
</section>
<section id="external-sources-used" class="level2">
<h2 class="anchored" data-anchor-id="external-sources-used">External sources used</h2>
<ul>
<li><p><a href="https://gist.githubusercontent.com/deekayen/4148741/raw/98d35708fa344717d8eee15d11987de6c8e26d7d/1-1000.txt">list of most common english words</a></p></li>
<li><p><a href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi%3A10.7910%2FDVN%2FBOK1CF&amp;utm_source=chatgpt.com">Dataset</a></p></li>
<li><p><a href="https://github.com/Blaizzy/mlx-embeddings">MLX-Embeddings repo</a></p></li>
<li><p><a href="https://github.com/ml-explore/mlx">MLX Repositories</a></p></li>
<li><p><a href="https://github.com/abeleinin/mlx-xLSTM">MLX Implementation of xLSTM</a></p></li>
<li><p><a href="https://docs.pytorch.org/docs/stable/generated/torch.nn.LSTM.html">Pytorch implementaino of LSTM</a></p></li>
</ul>
<div style="page-break-after: always;"></div>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




</body></html>